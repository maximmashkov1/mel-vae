{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380ace8-5968-4422-88c2-33f39d54ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import MELVAE\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import Optimizer, AdamW\n",
    "import torch\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e64d2e-a6bd-40bf-9edc-6fb9a92f5d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MELVAE(encoder_channels=[1,16,64,256,32], encoder_downs=[None,'freq','freq','full','full'], \n",
    "                 decoder_channels=[1,16,64,256,64,4],\n",
    "                 discr_channels=[1,16,64,192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19137f8e-c171-4540-94f8-a402ef0e987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim import Optimizer, AdamW\n",
    "import torch\n",
    "import math\n",
    "class LinearWarmupCosineAnnealingLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, total_steps, min_lr=0.0, last_epoch=-1):\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.total_steps = total_steps\n",
    "        self.min_lr = min_lr\n",
    "        super(LinearWarmupCosineAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            return [\n",
    "                base_lr * self.last_epoch / self.warmup_steps\n",
    "                for base_lr in self.base_lrs\n",
    "            ]\n",
    "        else:\n",
    "            progress = (self.last_epoch - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
    "            return [\n",
    "                self.min_lr + (base_lr - self.min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "                for base_lr in self.base_lrs\n",
    "            ]\n",
    "\n",
    "\n",
    "no_decay = ['bias', 'norm'] \n",
    "params = list(model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in params if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.003},\n",
    "    {\n",
    "        'params': [p for n, p in params if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "optimizer = AdamW(params=optimizer_grouped_parameters, lr=5e-4)\n",
    "scheduler = LinearWarmupCosineAnnealingLR(optimizer=optimizer, warmup_steps=2000, total_steps=200000, min_lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd553bd5-6efb-4d5d-a6ad-740c4c2ca02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"F:\\datasets\\AVSpeech\\processed_hifigan_22khz\\dataset.json\", 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cccc5d3-2275-4834-b065-1adc10094c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(dataset)):\n",
    "    dataset[r]['audio'][0] = np.load(dataset[r]['audio'][0])\n",
    "std=0\n",
    "mean=0\n",
    "\n",
    "for r in range(1000):\n",
    "    author = random.choice(dataset)\n",
    "    std += author['audio'][0].std()\n",
    "    mean += author['audio'][0].mean()\n",
    "std, mean = std/1000, mean/1000\n",
    "\n",
    "for r in range(len(dataset)):\n",
    "    dataset[r]['audio'][0]=(dataset[r]['audio'][0]-mean) /std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856c37f-d933-4606-bf8a-161ad31c4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import copy\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('F:/TENSORBOARD/melvae')\n",
    "plt.ion() \n",
    "fig, ax = plt.subplots()\n",
    "losses = []\n",
    "kl_losses = []\n",
    "disc_losses = []\n",
    "gen_disc_losses = []\n",
    "idx=0\n",
    "best_val_loss=999\n",
    "i=0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ca903-51a7-4e3d-a2ee-80574a1bc84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def kl_weight(step):\n",
    "    max_=50000\n",
    "    return 0.015*min(step,max_)/max_\n",
    "    \n",
    "model.train().to('cuda')\n",
    "\n",
    "N=8\n",
    "def assemble_batch(mel_cutoff=256):\n",
    "    c = 0\n",
    "    mels = []\n",
    "\n",
    "    while c < N:\n",
    "        artist = random.choice(dataset)\n",
    "        seq = random.choice(artist['audio'])\n",
    "        mel = seq[0]\n",
    "\n",
    "        if mel.shape[-1] < mel_cutoff:\n",
    "            continue\n",
    "\n",
    "        start_idx = random.randint(0, mel.shape[-1] - mel_cutoff)\n",
    "        end_idx = start_idx + mel_cutoff\n",
    "\n",
    "        mels.append(mel[:, start_idx:end_idx])\n",
    "        c += 1\n",
    "\n",
    "    return torch.tensor(mels).to('cuda').unsqueeze(1)\n",
    "\n",
    "while True:\n",
    "    optimizer.zero_grad()\n",
    "    mel = assemble_batch(random.randint(224,400))\n",
    "    \n",
    "\n",
    "    disc_loss, rec_loss, kl_loss, gen_adv_loss, (mu, logvar) = model.get_loss(mel)\n",
    "    kl_loss*=kl_weight(i)\n",
    "    gen_adv_loss*=0.5\n",
    "    \n",
    "    gen_loss = rec_loss + kl_loss + gen_adv_loss\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    disc_loss.backward(retain_graph=True) \n",
    "    gen_loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses.append(rec_loss.item())\n",
    "    kl_losses.append(kl_loss.item())\n",
    "    gen_disc_losses.append(gen_adv_loss.item())\n",
    "    disc_losses.append(disc_loss.item())\n",
    "    \n",
    "    if i%25==0:\n",
    "        torch.cuda.empty_cache()\n",
    "        writer.add_histogram(\"mu\", mu, global_step=i, bins=50)\n",
    "        writer.add_histogram(\"logvar\", logvar, global_step=i, bins=50)\n",
    "        \n",
    "        ax.clear()\n",
    "        clear_output(wait=True)  \n",
    "        \n",
    "        ax.plot(np.array(kl_losses[::8]), label='kl')\n",
    "        ax.plot(np.array(disc_losses[::8]), label='adv_disc')\n",
    "        ax.plot(np.array(gen_disc_losses[::8]), label='adv_gen')\n",
    "        ax.plot(np.array(losses[::8]), label='Loss')\n",
    "        ax.set_ylim(0,2)\n",
    "        ax.legend()\n",
    "        display(fig)  \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0997a8a-ccaf-4278-9220-f1947b4bdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import sobel\n",
    "\n",
    "spec=None\n",
    "mel = assemble_batch(random.randint(224,400))\n",
    "mel = mel[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900f463-3daf-4b88-9473-db3075661305",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "plt.imshow(mel.squeeze(0).squeeze(0).cpu().detach().numpy()[::-1],cmap='turbo')\n",
    "plt.show()\n",
    "mu, logvar, shapes = model.encode(mel.to('cuda'))\n",
    "out = model.decode(mu)\n",
    "out_=out.squeeze(0).squeeze(0).cpu().detach().numpy()\n",
    "plt.imshow(out_[::-1],cmap='turbo')\n",
    "plt.show()\n",
    "model.train()\n",
    "np.save('out.npy',out.squeeze(0).cpu().detach().numpy()*std + mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
